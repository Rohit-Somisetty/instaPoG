{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379caf04-4e19-43d2-bb9b-f5298e6c64ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='margin-bottom:10px; color:#333;'>ğŸ“° News to Instagram</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da00baf2d7894d8684de1f4526327b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(margin='0 10px 0 0', width='60%'), placeholder='Paste article URLâ€¦')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a0ed55d1f6406ea9d10d2874b8e3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.3, description='Temp', max=1.0, step=0.05), FloatSlider(value=0.9, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1538d7d58a745ecba8c663d27da5b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description='deepseek-r1:8b-gpu'), Checkbox(value=True, description='gemmaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df2573c0204446a8662910ef0f3a08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='ğŸ§  Summarize', layout=Layout(width='150px'), style=Bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffa008647d64094b2bfacaae59cecd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid #ccc', border_left='1px solid #ccc', border_right='1px solid #ccâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "import ollama\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Markdown, clear_output\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "from datetime import datetime\n",
    "\n",
    "# â”€â”€â”€ SOFT-PROMPT LOADING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    with open(\"soft_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        SOFT_PROMPT = f.read().strip()\n",
    "except FileNotFoundError:\n",
    "    SOFT_PROMPT = \"\"\n",
    "\n",
    "# â”€â”€â”€ DYNAMIC MODEL DISCOVERY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_installed_model_pairs():\n",
    "    try:\n",
    "        raw = ollama.list()\n",
    "        entries = raw.get(\"models\", raw)\n",
    "        pairs = []\n",
    "        for m in entries:\n",
    "            model_id = m.get(\"model\", m.get(\"name\"))\n",
    "            display_id = m.get(\"name\", model_id)\n",
    "            pairs.append((display_id, model_id))\n",
    "        return pairs\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "MODEL_PAIRS = get_installed_model_pairs()\n",
    "MODELS = [disp for disp, _ in MODEL_PAIRS]\n",
    "MODEL_ALIASES = {disp: model_id for disp, model_id in MODEL_PAIRS}\n",
    "MAX_WORKERS = 3\n",
    "\n",
    "# Persistent HTTP session\n",
    "SESSION = requests.Session()\n",
    "\n",
    "# â”€â”€â”€ SELENIUM CHROME OPTIONS FOR SCRAPING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CHROME_OPTS = uc.ChromeOptions()\n",
    "for arg in [\"--disable-gpu\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]:\n",
    "    CHROME_OPTS.add_argument(arg)\n",
    "CHROME_OPTS.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "CHROME_OPTS.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "CHROME_OPTS.add_experimental_option(\"useAutomationExtension\", False)\n",
    "# Optional headless:\n",
    "# CHROME_OPTS.add_argument(\"--headless\")\n",
    "\n",
    "# Cache for fetched articles\n",
    "_scraped_cache = {}\n",
    "\n",
    "# â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@lru_cache(maxsize=128)\n",
    "def _cleanup_reasoning(raw: str) -> str:\n",
    "    return re.sub(\n",
    "        r'^(?:\\s*(?:Okay|Alright|First|Next|Finally|Let me|I need)[^\\.\\!?]*[\\.\\!?])+',\n",
    "        '', raw, flags=re.IGNORECASE\n",
    "    ).strip()\n",
    "\n",
    "# â”€â”€â”€ ARTICLE FETCHER WITH JS/ADBLOCK OVERRIDE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fetch_article(url: str, timeout: int = 15) -> tuple[str, str]:\n",
    "    if url in _scraped_cache:\n",
    "        return _scraped_cache[url]\n",
    "    try:\n",
    "        driver = uc.Chrome(options=CHROME_OPTS)\n",
    "        driver.execute_cdp_cmd(\n",
    "            'Page.addScriptToEvaluateOnNewDocument',\n",
    "            {'source': \"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\"}\n",
    "        )\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'article, main'))\n",
    "        )\n",
    "        driver.execute_script(\n",
    "            '''\n",
    "            document.querySelectorAll(\n",
    "              '.overlay, .modal, .adblock-warning, body > div[style*=\"position: fixed\"], .cookie-consent'\n",
    "            ).forEach(el => el.remove());\n",
    "            '''\n",
    "        )\n",
    "        try:\n",
    "            container = driver.find_element(By.TAG_NAME, 'article')\n",
    "        except:\n",
    "            container = driver.find_element(By.TAG_NAME, 'main')\n",
    "        html = container.get_attribute('outerHTML')\n",
    "        title = driver.title or \"No Title\"\n",
    "        driver.execute_script('window.scrollBy(0, 500)')\n",
    "        content = BeautifulSoup(html, 'html.parser').get_text(\"\\n\", strip=True)\n",
    "        driver.quit()\n",
    "    except Exception:\n",
    "        resp = SESSION.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        title = soup.title.string.strip() if soup.title and soup.title.string else \"No Title\"\n",
    "        content = \"\\n\".join(p.get_text(strip=True) for p in soup.find_all(\"p\"))\n",
    "    _scraped_cache[url] = (title, content)\n",
    "    return title, content\n",
    "\n",
    "# â”€â”€â”€ LLM CHAT WRAPPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def llm_chat(model_id, messages, temperature, top_p, max_tokens):\n",
    "    params = {\"model\": model_id, \"messages\": messages}\n",
    "    options = {\"temperature\": temperature, \"top_p\": top_p, \"max_tokens\": max_tokens}\n",
    "    if SOFT_PROMPT:\n",
    "        params[\"messages\"] = [{\"role\": \"system\", \"content\": SOFT_PROMPT}] + messages\n",
    "    return ollama.chat(**params, options=options)[\"message\"][\"content\"].strip()\n",
    "\n",
    "# â”€â”€â”€ SUMMARIZATION & REFINEMENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def summarize(text: str, label: str, temperature: float, top_p: float, max_tokens: int) -> str:\n",
    "    model_id = MODEL_ALIASES[label]\n",
    "    system = (\n",
    "        \"Youâ€™re a senior news editor at a major outletâ€”produce a natural-sounding, balanced summary of the provided text in 5â€“7 sentences. \"\n",
    "        \"Use whatever content is available; do not ask for more text or apologize if itâ€™s brief. Output ONLY the summary.\"\n",
    "    )\n",
    "    user = f\"Article (first 2000 chars):\\n{text[:2000]}\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}]\n",
    "    draft = llm_chat(model_id, messages, temperature, top_p, max_tokens)\n",
    "    return _cleanup_reasoning(draft)\n",
    "\n",
    "# â”€â”€â”€ BUILD INSTAGRAM POST MERGED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_instagram_post(summary: str, label: str, temperature: float, top_p: float, max_tokens: int) -> str:\n",
    "    model_id = MODEL_ALIASES[label]\n",
    "    system = (\n",
    "        \"You are a professional social media strategistâ€”create a natural, engaging Instagram caption of 2â€“3 sentences, incorporating emojis and relevant hashtags. \"\n",
    "        \"Use the provided summary directly; output ONLY the caption.\"\n",
    "    )\n",
    "    user = f\"Summary:\\n{summary}\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}]\n",
    "    resp = ollama.chat(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        options={\"temperature\": temperature, \"top_p\": top_p, \"max_tokens\": max_tokens}\n",
    "    )\n",
    "    return resp[\"message\"][\"content\"].strip()\n",
    "\n",
    "# â”€â”€â”€ PARALLEL PROCESSING WITH STREAMING & LOADING MESSAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def parallel_llm(func, text, labels, temperature, top_p, max_tokens, output_widget, title):\n",
    "    output_widget.clear_output()\n",
    "    display(Markdown(f\"â³ Generating {title.lower()}...\"))\n",
    "    progress = widgets.IntProgress(min=0, max=len(labels), description=title)\n",
    "    display(progress)\n",
    "    with output_widget:\n",
    "        futures = {}\n",
    "        for label in labels:\n",
    "            futures[ThreadPoolExecutor().submit(func, text, label, temperature, top_p, max_tokens)] = label\n",
    "        for fut in as_completed(futures):\n",
    "            label = futures[fut]\n",
    "            try:\n",
    "                res = fut.result()\n",
    "            except Exception:\n",
    "                res = \"âŒ Error\"\n",
    "            display(Markdown(f\"**Model: {label}**  \\n---\\n{res}\"))\n",
    "            progress.value += 1\n",
    "    progress.close()\n",
    "    display(Markdown(f\"âœ… Completed generating {title.lower()}!\"))\n",
    "\n",
    "# â”€â”€â”€ UI SETUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "HEADER = HTML(\"<h2 style='margin-bottom:10px; color:#333;'>ğŸ“° News to Instagram</h2>\")\n",
    "url_input = widgets.Text(\n",
    "    placeholder=\"Paste article URLâ€¦\",\n",
    "    layout=widgets.Layout(width=\"60%\", margin=\"0 10px 0 0\")\n",
    ")\n",
    "params_box = widgets.HBox([\n",
    "    widgets.FloatSlider(value=0.3, min=0.0, max=1.0, step=0.05, description='Temp'),\n",
    "    widgets.FloatSlider(value=0.9, min=0.0, max=1.0, step=0.05, description='Top-p'),\n",
    "    widgets.IntSlider(value=400, min=100, max=1000, step=50, description='Max-tokens')\n",
    "], layout=widgets.Layout(margin=\"10px 0\", gap=\"20px\"))\n",
    "checkboxes = widgets.VBox([\n",
    "    widgets.Checkbox(value=True, description=lbl) for lbl in MODELS\n",
    "], layout=widgets.Layout(margin=\"10px 0\"))\n",
    "buttons = widgets.HBox([\n",
    "    widgets.Button(description=\"ğŸ§  Summarize\", button_style=\"primary\", layout=widgets.Layout(width=\"150px\")),\n",
    "    widgets.Button(description=\"ğŸ“¸ Generate Post\", button_style=\"info\", layout=widgets.Layout(width=\"150px\")),\n",
    "    widgets.Button(description=\"ğŸ§¹ Clear\", button_style=\"warning\", layout=widgets.Layout(width=\"150px\"))\n",
    "], layout=widgets.Layout(margin=\"10px 0\", gap=\"20px\"))\n",
    "output = widgets.Output(layout=widgets.Layout(border=\"1px solid #ccc\", padding=\"10px\", height=\"500px\", overflow_y=\"auto\"))\n",
    "\n",
    "# CALLBACKS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def on_summarize(_):\n",
    "    url = url_input.value.strip()\n",
    "    if not url:\n",
    "        with output: clear_output(); display(Markdown(\"âš ï¸ URL required\")); return\n",
    "    title, text = fetch_article(url)\n",
    "    labels = [cb.description for cb in checkboxes.children if cb.value]\n",
    "    if not labels:\n",
    "        with output: clear_output(); display(Markdown(\"âš ï¸ Select model(s)\")); return\n",
    "    with output: clear_output(); display(Markdown(f\"## ğŸ§  Summaries for: **{title}**\"))\n",
    "    parallel_llm(\n",
    "        summarize, text, labels,\n",
    "        params_box.children[0].value,\n",
    "        params_box.children[1].value,\n",
    "        params_box.children[2].value,\n",
    "        output, title=\"Summaries\"\n",
    "    )\n",
    "\n",
    "def on_instagram(_):\n",
    "    url = url_input.value.strip()\n",
    "    if not url:\n",
    "        with output: clear_output(); display(Markdown(\"âš ï¸ URL required\")); return\n",
    "    title, text = fetch_article(url)\n",
    "    labels = [cb.description for cb in checkboxes.children if cb.value]\n",
    "    if not labels:\n",
    "        with output: clear_output(); display(Markdown(\"âš ï¸ Select model(s)\")); return\n",
    "    with output: clear_output(); display(Markdown(f\"## ğŸ“¸ Instagram Posts for: **{title}**\"))\n",
    "    parallel_llm(\n",
    "        build_instagram_post, text, labels,\n",
    "        params_box.children[0].value,\n",
    "        params_box.children[1].value,\n",
    "        params_box.children[2].value,\n",
    "        output, title=\"Instagram\"\n",
    "    )\n",
    "\n",
    "def on_clear(_):\n",
    "    url_input.value = \"\"\n",
    "    for cb in checkboxes.children:\n",
    "        cb.value = True\n",
    "    output.clear_output()\n",
    "\n",
    "# Hook up buttons\n",
    "buttons.children[0].on_click(on_summarize)\n",
    "buttons.children[1].on_click(on_instagram)\n",
    "buttons.children[2].on_click(on_clear)\n",
    "\n",
    "# Render UI\n",
    "display(HEADER, url_input, params_box, checkboxes, buttons, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c77036-92b5-4b4b-8bb3-cb141a8766cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
